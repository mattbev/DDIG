{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    #Batch shape of x: (3, 32, 32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        #Input channels = 3, Output channels = 18\n",
    "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        #Channels = 18, Height = Width = 32\n",
    "#         self.pool = ExpPool(18, 32, 32)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        #18 input features, 10 output features (for 10 defined classes)\n",
    "#         self.fc = torch.nn.Linear(18, 10)\n",
    "        self.fc1 = torch.nn.Linear(18*16*16, 64)\n",
    "        self.fc2 = torch.nn.Linear(64, 10)\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes activation of the first convolution\n",
    "        \"\"\"\n",
    "        #Dimension changes from (3, 32, 32) to (18, 32, 32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Dimension changes from (18, 32, 32) to (18, 1)\n",
    "#         x = self.pool.forward(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 18*16*16)\n",
    "        \n",
    "#         #Dimension changes from (1,18) to (1, 10)\n",
    "#         x = F.relu(self.fc(x))\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "#         sm = F.softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def output_size(in_size, kernel_size, stride, padding):\n",
    "        \"\"\"\n",
    "        Determines the output size\n",
    "        \"\"\"\n",
    "        output = int((in_size - kernel_size + 2*padding) / stride) + 1\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hist():    \n",
    "    @staticmethod\n",
    "    def between(i, lower, upper=None):\n",
    "        return lower <= i < upper if upper else lower <= i\n",
    "    \n",
    "    @staticmethod\n",
    "    def vector_histogram_oldest(x, bins):\n",
    "        x_max = torch.max(x).item()\n",
    "        x_min = torch.min(x).item()\n",
    "        tau = np.linspace(x_min, x_max, bins+1)\n",
    "        histogram = torch.zeros(bins)\n",
    "        \n",
    "        for b in range(bins):  \n",
    "            if b < bins-1:\n",
    "                mask = torch.Tensor([1 if hist.between(x_i, lower=tau[b], upper=tau[b+1]) else 0 for x_i in x])\n",
    "            else:\n",
    "                mask = torch.Tensor([1 if hist.between(x_i, lower=tau[b]) else 0 for x_i in x])\n",
    "            histogram[b] = torch.sum(mask*torch.tanh(x))\n",
    "            \n",
    "        return histogram\n",
    "    \n",
    "    @staticmethod\n",
    "    def vector_histogram_old(x, bins):\n",
    "        x_max = torch.max(x).item()\n",
    "        x_min = torch.min(x).item()\n",
    "        tau = np.linspace(x_min, x_max, bins+1)\n",
    "        histogram = torch.zeros(bins)\n",
    "        x_tanh = torch.tanh(x)\n",
    "        \n",
    "        for b in range(bins):\n",
    "            if b < bins-1:\n",
    "                mask = (tau[b] <= x) & (x < tau[b+1])\n",
    "            else:\n",
    "                mask = (tau[b] <= x)\n",
    "            histogram[b] = torch.sum(torch.zeros_like(x).masked_scatter_(mask, x_tanh))\n",
    "        \n",
    "        return histogram\n",
    "        \n",
    "    @staticmethod\n",
    "    def tensor_histogram(x, bins):\n",
    "        N, C, H = x.shape\n",
    "        x_max = torch.max(x).item()\n",
    "        x_min = torch.min(x).item()\n",
    "        tau = np.linspace(x_min, x_max, bins+1)\n",
    "        histogram = torch.zeros(N, C, bins)\n",
    "        x_tanh = torch.tanh(x)\n",
    "\n",
    "        for b in range(bins):\n",
    "            if b < bins-1:\n",
    "                mask = (tau[b] <= x) & (x < tau[b+1])\n",
    "            else:\n",
    "                mask = (tau[b] <= x)\n",
    "            histogram[:,:,b] = torch.sum(torch.zeros_like(x).masked_scatter_(mask, x_tanh), dim=2)        \n",
    "        \n",
    "        return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAP:\n",
    "    def __init__(self, kernel_size, stride): \n",
    "        '''\n",
    "        implicit 0-padding\n",
    "        '''\n",
    "        self.k = kernel_size\n",
    "        self.s = stride\n",
    "    \n",
    "    def forward(self, sample):\n",
    "        i=0\n",
    "        y = []\n",
    "        subject = sample[0]\n",
    "        print(\"subject\", subject)\n",
    "        \n",
    "        while i < len(subject):\n",
    "            upper_index = min(len(subject), i+self.k)\n",
    "            subsection = subject[i:upper_index]\n",
    "            print(subsection, len(subsection))\n",
    "            tot = sum(subsection)\n",
    "            print(tot)\n",
    "            avg = tot / len(subsection)\n",
    "            y.append(avg)\n",
    "            i += self.s\n",
    "        \n",
    "        print(\"\\n\\n\", \"y\", y)\n",
    "        y = torch.stack(y)\n",
    "        print(\"\\n\\n\", \"y\", y)\n",
    "        \n",
    "        sm = F.softmax(y)\n",
    "        \n",
    "        \n",
    "        return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "class HistPool2d(torch.nn.AvgPool2d):\n",
    "\n",
    "    def __init__(self, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True):\n",
    "        self.counter = 0\n",
    "        super(HistPool2d, self).__init__(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)\n",
    "        \n",
    "    def forward(self, sample):\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        rows, cols = sample.shape\n",
    "        x = torch.sum(sample, axis=0)/rows\n",
    "        print(x)\n",
    "        print(sample)\n",
    "        print(F.softmax(x))\n",
    "        sys.exit(0)\n",
    "             \n",
    "#             #Sample data\n",
    "# #             sample = inputs[0]            \n",
    "# #             imshow(sample)\n",
    "            \n",
    "#             #Isolate color channels\n",
    "#             r_channel = sample[0]\n",
    "#             g_channel = sample[1]\n",
    "#             b_channel = sample[2]  \n",
    "            \n",
    "#             #Create histograms\n",
    "#             hist_r = torch.histc(r_channel, bins = 255, min = 0.0, max = 1.0)\n",
    "#             hist_g = torch.histc(g_channel, bins = 255, min = 0.0, max = 1.0)\n",
    "#             hist_b = torch.histc(b_channel, bins = 255, min = 0.0, max = 1.0)\n",
    "            \n",
    "#             # Normalize the histograms so that they sum to 1.\n",
    "#             hist_r = hist_r.div(hist_r.sum())\n",
    "#             hist_g = hist_g.div(hist_g.sum())\n",
    "#             hist_b = hist_b.div(hist_b.sum())\n",
    "            \n",
    "#             # Plot the histograms.\n",
    "#             fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey = True)\n",
    "#             ax1.bar(np.linspace(1.0, 255.0, num = 255), hist_r.numpy(), color='r')\n",
    "#             ax2.bar(np.linspace(1.0, 255.0, num = 255), hist_g.numpy(), color='g')\n",
    "#             ax3.bar(np.linspace(1.0, 255.0, num = 255), hist_b.numpy(), color='b')\n",
    "#             fig.show();\n",
    "            \n",
    "#             self.counter += 1\n",
    "#             if self.counter == 5:\n",
    "#                 sys.exit()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
