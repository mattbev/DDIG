{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental Pooling\n",
    "=========================\n",
    "\n",
    "A better version of CNN pooling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(root=\"./cifardata\", train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root=\"./cifardata\", train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', \n",
    "           'car', \n",
    "           'bird',\n",
    "           'cat',\n",
    "           'deer', \n",
    "           'dog', \n",
    "           'frog', \n",
    "           'horse',\n",
    "           'ship',\n",
    "           'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "#Training\n",
    "n_training_samples = 1000 #20000\n",
    "train_sampler = SubsetRandomSampler(np.arange(n_training_samples, dtype=np.int64))\n",
    "def get_train_loader(batch_size):\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
    "        return train_loader\n",
    "    \n",
    "#Validation\n",
    "n_val_samples = 5000\n",
    "val_sampler = SubsetRandomSampler(np.arange(n_training_samples, n_training_samples+n_val_samples, dtype=np.int64))\n",
    "val_loader = torch.utils.data.DataLoader(train_set, batch_size=128, sampler=val_sampler, num_workers=2)\n",
    "\n",
    "#Testing\n",
    "n_test_samples = 5000\n",
    "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=4, sampler=test_sampler, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortPool:\n",
    "    def __init__(self, channels, height, width):\n",
    "        self.channels = channels\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.coeff = torch.rand(self.channels, self.height*self.width, requires_grad=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "#         print(\"x1\", x.shape)\n",
    "        x = x.view(batch_size, channels, height*width)\n",
    "#         print(\"x2\", x.shape)\n",
    "#         x, indices = torch.sort(x, dim=2, descending=True)\n",
    "#         print(\"x3\", x.shape)\n",
    "        x = torch.mul(x, self.coeff)\n",
    "#         print(\"x4\", x.shape)\n",
    "        y = torch.mean(x, dim=2)\n",
    "#         print(\"y\", y.shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    #Batch shape of x: (3, 32, 32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        #Input channels = 3, Output channels = 18\n",
    "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.pool = SortPool(18, 32, 32)\n",
    "                        \n",
    "        #1024 input features, 1 output feature\n",
    "#         self.fc1 = torch.nn.Linear(32*32, 1)\n",
    "        \n",
    "        #1024 input features, 10 output features (for 10 defined classes)\n",
    "        self.fc = torch.nn.Linear(18, 10)\n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Computes activation of the first convolution\n",
    "        \"\"\"\n",
    "        #Dimension changes from (3, 32, 32) to (18, 32, 32)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Dimension changes from (18, 32, 32) to (1, 18)\n",
    "        x = self.pool.forward(x)\n",
    "\n",
    "        \n",
    "        #Dimension changes from (18, 32*32) to (18, 1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #Dimension changes from (18, 1) to (1, 18)\n",
    "#         x = x.view(-1, 18*32*32)\n",
    "        \n",
    "        #Dimension changes from (1,1024) to (1, 10)\n",
    "        x = F.relu(self.fc(x))\n",
    "        \n",
    "#         sm = F.softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def output_size(in_size, kernel_size, stride, padding):\n",
    "        \"\"\"\n",
    "        Determines the output size\n",
    "        \"\"\"\n",
    "        output = int((in_size - kernel_size + 2*padding) / stride) + 1\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def loss_and_optimizer(net, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Initializes the loss optimizer functions\n",
    "    \"\"\"\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "    \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size =\", batch_size)\n",
    "    print(\"epochs =\", n_epochs)\n",
    "    print(\"learning_rate =\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    validation_losses = []\n",
    "    training_losses = []\n",
    "    \n",
    "    #Retrieve training data\n",
    "    train_loader = get_train_loader(batch_size)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    #Initialize loss and optimizer functions\n",
    "    loss, optimizer = loss_and_optimizer(net, learning_rate)\n",
    "    \n",
    "    \n",
    "    training_start_time = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10\n",
    "        print_every = 1 if print_every == 0 else print_every\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "#             if epoch == 0:\n",
    "#                 global img\n",
    "#                 img = inputs\n",
    "#                 target = inputs[0]\n",
    "#                 imshow(target)\n",
    "#                 print(classes[labels[0]])\n",
    "#             inputs, labels = Variable(inputs), Variable(labels)   \n",
    "                        \n",
    "            #Set parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs)            \n",
    "            loss_size = loss(outputs, labels)\n",
    "            \n",
    "            #Intermediate accuracy\n",
    "#             _, predicted = torch.max(outputs.data, dim=1)\n",
    "#             num_correct = (predicted == labels).sum().item()\n",
    "#             intermediate_acc = (num_correct * 100.0 / labels.size(0))\n",
    "            \n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Update statistics\n",
    "            running_loss += loss_size.data.item()\n",
    "            total_train_loss += loss_size.data.item()\n",
    "            \n",
    "            #Print statistics every 10th batch of epoch\n",
    "            if (i+1) % (print_every+1) == 0:\n",
    "                print(\"Epoch {epoch}, {percent_complete_epoch:d}% \\t train_loss: {train_loss:.2f} \\t took: {time:.2f}s\".format(\n",
    "                    epoch = epoch+1, \n",
    "                    percent_complete_epoch = int(100 * (i+1) / n_batches), \n",
    "                    train_loss = running_loss / print_every, \n",
    "                    time = time.time() - start_time, \n",
    "#                     accuracy = intermediate_acc.item()\n",
    "                ))\n",
    "                \n",
    "                #Reset running loss and time\n",
    "                running_loss = 0.0\n",
    "                start_time = time.time()\n",
    "            \n",
    "        #After each epoch, run a pass on validation set\n",
    "        total_val_loss = 0\n",
    "        \n",
    "        for inputs, labels in val_loader:\n",
    "            \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            #Forward pass\n",
    "            val_outputs = net(inputs)\n",
    "            val_loss_size = loss(val_outputs, labels)\n",
    "            total_val_loss += val_loss_size.data.item()\n",
    "        \n",
    "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(val_loader)))\n",
    "        \n",
    "        validation_losses.append(total_val_loss / len(val_loader))\n",
    "        training_losses.append(running_loss / print_every)\n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"=\" * 30)\n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = plt.axes()\n",
    "    x = np.linspace(0, n_epochs, n_epochs)\n",
    "    plt.plot(x, training_losses)\n",
    "    plt.plot(x, validation_losses)\n",
    "    ax.legend([\"train_loss\", \"val_loss\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    class_correct = list(0. for i in range(len(classes)))\n",
    "    class_total = list(0. for i in range(len(classes)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data in test_loader:\n",
    "\n",
    "            #Run test data through model\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            \n",
    "            \n",
    "            #Updte statistics\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            #Class specific \n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(predicted)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "        \n",
    "        #Report accuracies\n",
    "        overall_acc = (correct * 100.0) / total\n",
    "        class_acc = {}\n",
    "        for i in range(len(classes)):\n",
    "            class_acc[classes[i]] = (class_correct[i] * 100) / class_total[i]\n",
    "                \n",
    "\n",
    "    return overall_acc, class_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size = 32\n",
      "epochs = 100\n",
      "learning_rate = 0.01\n",
      "==============================\n",
      "Epoch 1, 12% \t train_loss: 3.07 \t took: 0.15s\n",
      "Epoch 1, 25% \t train_loss: 3.05 \t took: 0.05s\n",
      "Epoch 1, 37% \t train_loss: 3.07 \t took: 0.06s\n",
      "Epoch 1, 50% \t train_loss: 3.03 \t took: 0.05s\n",
      "Epoch 1, 62% \t train_loss: 3.07 \t took: 0.04s\n",
      "Epoch 1, 75% \t train_loss: 3.03 \t took: 0.05s\n",
      "Epoch 1, 87% \t train_loss: 3.03 \t took: 0.04s\n",
      "Epoch 1, 100% \t train_loss: 3.02 \t took: 0.03s\n",
      "Validation loss = 2.27\n",
      "Epoch 2, 12% \t train_loss: 3.00 \t took: 0.12s\n",
      "Epoch 2, 25% \t train_loss: 2.99 \t took: 0.04s\n",
      "Epoch 2, 37% \t train_loss: 2.99 \t took: 0.05s\n",
      "Epoch 2, 50% \t train_loss: 3.00 \t took: 0.06s\n",
      "Epoch 2, 62% \t train_loss: 2.96 \t took: 0.05s\n",
      "Epoch 2, 75% \t train_loss: 3.08 \t took: 0.06s\n",
      "Epoch 2, 87% \t train_loss: 3.01 \t took: 0.04s\n",
      "Epoch 2, 100% \t train_loss: 3.03 \t took: 0.04s\n",
      "Validation loss = 2.25\n",
      "Epoch 3, 12% \t train_loss: 2.92 \t took: 0.09s\n",
      "Epoch 3, 25% \t train_loss: 3.00 \t took: 0.04s\n",
      "Epoch 3, 37% \t train_loss: 3.02 \t took: 0.04s\n",
      "Epoch 3, 50% \t train_loss: 2.99 \t took: 0.06s\n",
      "Epoch 3, 62% \t train_loss: 3.00 \t took: 0.05s\n",
      "Epoch 3, 75% \t train_loss: 2.96 \t took: 0.06s\n",
      "Epoch 3, 87% \t train_loss: 2.98 \t took: 0.04s\n",
      "Epoch 3, 100% \t train_loss: 2.93 \t took: 0.03s\n",
      "Validation loss = 2.23\n",
      "Epoch 4, 12% \t train_loss: 2.96 \t took: 0.10s\n",
      "Epoch 4, 25% \t train_loss: 2.90 \t took: 0.05s\n",
      "Epoch 4, 37% \t train_loss: 2.97 \t took: 0.04s\n",
      "Epoch 4, 50% \t train_loss: 3.02 \t took: 0.04s\n",
      "Epoch 4, 62% \t train_loss: 2.93 \t took: 0.06s\n",
      "Epoch 4, 75% \t train_loss: 2.94 \t took: 0.06s\n",
      "Epoch 4, 87% \t train_loss: 2.92 \t took: 0.05s\n",
      "Epoch 4, 100% \t train_loss: 2.98 \t took: 0.03s\n",
      "Validation loss = 2.23\n",
      "Epoch 5, 12% \t train_loss: 2.91 \t took: 0.10s\n",
      "Epoch 5, 25% \t train_loss: 2.87 \t took: 0.04s\n",
      "Epoch 5, 37% \t train_loss: 2.89 \t took: 0.10s\n",
      "Epoch 5, 50% \t train_loss: 2.93 \t took: 0.12s\n",
      "Epoch 5, 62% \t train_loss: 2.93 \t took: 0.10s\n",
      "Epoch 5, 75% \t train_loss: 2.93 \t took: 0.07s\n",
      "Epoch 5, 87% \t train_loss: 2.98 \t took: 0.06s\n",
      "Epoch 5, 100% \t train_loss: 3.01 \t took: 0.04s\n",
      "Validation loss = 2.21\n",
      "Epoch 6, 12% \t train_loss: 3.00 \t took: 0.10s\n",
      "Epoch 6, 25% \t train_loss: 2.97 \t took: 0.07s\n",
      "Epoch 6, 37% \t train_loss: 2.88 \t took: 0.12s\n",
      "Epoch 6, 50% \t train_loss: 2.99 \t took: 0.11s\n",
      "Epoch 6, 62% \t train_loss: 2.90 \t took: 0.09s\n",
      "Epoch 6, 75% \t train_loss: 2.81 \t took: 0.09s\n",
      "Epoch 6, 87% \t train_loss: 2.90 \t took: 0.06s\n",
      "Epoch 6, 100% \t train_loss: 2.85 \t took: 0.04s\n",
      "Validation loss = 2.20\n",
      "Epoch 7, 12% \t train_loss: 2.85 \t took: 0.10s\n",
      "Epoch 7, 25% \t train_loss: 2.82 \t took: 0.04s\n",
      "Epoch 7, 37% \t train_loss: 2.83 \t took: 0.08s\n",
      "Epoch 7, 50% \t train_loss: 2.99 \t took: 0.14s\n",
      "Epoch 7, 62% \t train_loss: 2.96 \t took: 0.09s\n",
      "Epoch 7, 75% \t train_loss: 2.88 \t took: 0.09s\n",
      "Epoch 7, 87% \t train_loss: 2.86 \t took: 0.06s\n",
      "Epoch 7, 100% \t train_loss: 3.12 \t took: 0.04s\n",
      "Validation loss = 2.20\n",
      "Epoch 8, 12% \t train_loss: 2.86 \t took: 0.10s\n",
      "Epoch 8, 25% \t train_loss: 2.81 \t took: 0.04s\n",
      "Epoch 8, 37% \t train_loss: 2.91 \t took: 0.04s\n",
      "Epoch 8, 50% \t train_loss: 2.90 \t took: 0.04s\n",
      "Epoch 8, 62% \t train_loss: 2.86 \t took: 0.06s\n",
      "Epoch 8, 75% \t train_loss: 2.84 \t took: 0.05s\n",
      "Epoch 8, 87% \t train_loss: 2.94 \t took: 0.06s\n",
      "Epoch 8, 100% \t train_loss: 3.04 \t took: 0.03s\n",
      "Validation loss = 2.18\n",
      "Epoch 9, 12% \t train_loss: 2.91 \t took: 0.10s\n",
      "Epoch 9, 25% \t train_loss: 2.83 \t took: 0.05s\n",
      "Epoch 9, 37% \t train_loss: 2.87 \t took: 0.05s\n",
      "Epoch 9, 50% \t train_loss: 2.81 \t took: 0.07s\n",
      "Epoch 9, 62% \t train_loss: 2.89 \t took: 0.06s\n",
      "Epoch 9, 75% \t train_loss: 2.88 \t took: 0.05s\n",
      "Epoch 9, 87% \t train_loss: 2.94 \t took: 0.04s\n",
      "Epoch 9, 100% \t train_loss: 2.89 \t took: 0.03s\n",
      "Validation loss = 2.17\n",
      "Epoch 10, 12% \t train_loss: 2.85 \t took: 0.10s\n",
      "Epoch 10, 25% \t train_loss: 2.80 \t took: 0.04s\n",
      "Epoch 10, 37% \t train_loss: 2.89 \t took: 0.04s\n",
      "Epoch 10, 50% \t train_loss: 2.80 \t took: 0.05s\n",
      "Epoch 10, 62% \t train_loss: 2.96 \t took: 0.06s\n",
      "Epoch 10, 75% \t train_loss: 2.86 \t took: 0.06s\n",
      "Epoch 10, 87% \t train_loss: 2.89 \t took: 0.04s\n",
      "Epoch 10, 100% \t train_loss: 2.87 \t took: 0.03s\n",
      "Validation loss = 2.18\n",
      "Epoch 11, 12% \t train_loss: 2.81 \t took: 0.12s\n",
      "Epoch 11, 25% \t train_loss: 2.84 \t took: 0.06s\n",
      "Epoch 11, 37% \t train_loss: 2.88 \t took: 0.05s\n",
      "Epoch 11, 50% \t train_loss: 2.85 \t took: 0.06s\n",
      "Epoch 11, 62% \t train_loss: 2.82 \t took: 0.05s\n",
      "Epoch 11, 75% \t train_loss: 2.88 \t took: 0.07s\n",
      "Epoch 11, 87% \t train_loss: 2.94 \t took: 0.07s\n",
      "Epoch 11, 100% \t train_loss: 2.74 \t took: 0.03s\n",
      "Validation loss = 2.16\n",
      "Epoch 12, 12% \t train_loss: 2.76 \t took: 0.10s\n",
      "Epoch 12, 25% \t train_loss: 2.89 \t took: 0.05s\n",
      "Epoch 12, 37% \t train_loss: 2.85 \t took: 0.05s\n",
      "Epoch 12, 50% \t train_loss: 2.84 \t took: 0.06s\n",
      "Epoch 12, 62% \t train_loss: 2.86 \t took: 0.05s\n",
      "Epoch 12, 75% \t train_loss: 2.91 \t took: 0.06s\n",
      "Epoch 12, 87% \t train_loss: 2.78 \t took: 0.05s\n",
      "Epoch 12, 100% \t train_loss: 2.77 \t took: 0.04s\n",
      "Validation loss = 2.16\n",
      "Epoch 13, 12% \t train_loss: 2.83 \t took: 0.10s\n",
      "Epoch 13, 25% \t train_loss: 2.71 \t took: 0.04s\n",
      "Epoch 13, 37% \t train_loss: 2.85 \t took: 0.04s\n",
      "Epoch 13, 50% \t train_loss: 2.73 \t took: 0.06s\n",
      "Epoch 13, 62% \t train_loss: 2.81 \t took: 0.04s\n",
      "Epoch 13, 75% \t train_loss: 2.89 \t took: 0.05s\n",
      "Epoch 13, 87% \t train_loss: 2.93 \t took: 0.07s\n",
      "Epoch 13, 100% \t train_loss: 2.98 \t took: 0.05s\n",
      "Validation loss = 2.16\n",
      "Epoch 14, 12% \t train_loss: 2.83 \t took: 0.10s\n",
      "Epoch 14, 25% \t train_loss: 2.71 \t took: 0.05s\n",
      "Epoch 14, 37% \t train_loss: 2.85 \t took: 0.05s\n",
      "Epoch 14, 50% \t train_loss: 2.73 \t took: 0.05s\n",
      "Epoch 14, 62% \t train_loss: 2.82 \t took: 0.05s\n",
      "Epoch 14, 75% \t train_loss: 2.86 \t took: 0.05s\n",
      "Epoch 14, 87% \t train_loss: 2.87 \t took: 0.05s\n",
      "Epoch 14, 100% \t train_loss: 2.92 \t took: 0.03s\n",
      "Validation loss = 2.15\n",
      "Epoch 15, 12% \t train_loss: 2.79 \t took: 0.09s\n",
      "Epoch 15, 25% \t train_loss: 2.75 \t took: 0.05s\n",
      "Epoch 15, 37% \t train_loss: 2.83 \t took: 0.04s\n",
      "Epoch 15, 50% \t train_loss: 2.83 \t took: 0.06s\n",
      "Epoch 15, 62% \t train_loss: 2.62 \t took: 0.04s\n",
      "Epoch 15, 75% \t train_loss: 2.91 \t took: 0.07s\n",
      "Epoch 15, 87% \t train_loss: 2.88 \t took: 0.04s\n",
      "Epoch 15, 100% \t train_loss: 2.93 \t took: 0.03s\n",
      "Validation loss = 2.15\n",
      "Epoch 16, 12% \t train_loss: 2.84 \t took: 0.10s\n",
      "Epoch 16, 25% \t train_loss: 2.87 \t took: 0.05s\n",
      "Epoch 16, 37% \t train_loss: 2.88 \t took: 0.04s\n",
      "Epoch 16, 50% \t train_loss: 2.76 \t took: 0.06s\n",
      "Epoch 16, 62% \t train_loss: 2.78 \t took: 0.04s\n",
      "Epoch 16, 75% \t train_loss: 2.76 \t took: 0.06s\n",
      "Epoch 16, 87% \t train_loss: 2.80 \t took: 0.04s\n",
      "Epoch 16, 100% \t train_loss: 2.83 \t took: 0.03s\n",
      "Validation loss = 2.15\n",
      "Epoch 17, 12% \t train_loss: 2.82 \t took: 0.09s\n",
      "Epoch 17, 25% \t train_loss: 2.80 \t took: 0.05s\n",
      "Epoch 17, 37% \t train_loss: 2.82 \t took: 0.05s\n",
      "Epoch 17, 50% \t train_loss: 2.83 \t took: 0.06s\n",
      "Epoch 17, 62% \t train_loss: 2.69 \t took: 0.04s\n",
      "Epoch 17, 75% \t train_loss: 2.83 \t took: 0.06s\n",
      "Epoch 17, 87% \t train_loss: 2.82 \t took: 0.04s\n",
      "Epoch 17, 100% \t train_loss: 2.86 \t took: 0.03s\n",
      "Validation loss = 2.14\n",
      "Epoch 18, 12% \t train_loss: 2.86 \t took: 0.09s\n",
      "Epoch 18, 25% \t train_loss: 2.78 \t took: 0.04s\n",
      "Epoch 18, 37% \t train_loss: 2.78 \t took: 0.04s\n",
      "Epoch 18, 50% \t train_loss: 2.84 \t took: 0.04s\n",
      "Epoch 18, 62% \t train_loss: 2.72 \t took: 0.06s\n",
      "Epoch 18, 75% \t train_loss: 2.95 \t took: 0.06s\n",
      "Epoch 18, 87% \t train_loss: 2.73 \t took: 0.05s\n",
      "Epoch 18, 100% \t train_loss: 2.71 \t took: 0.03s\n",
      "Validation loss = 2.14\n",
      "Epoch 19, 12% \t train_loss: 2.72 \t took: 0.09s\n",
      "Epoch 19, 25% \t train_loss: 2.76 \t took: 0.04s\n",
      "Epoch 19, 37% \t train_loss: 2.93 \t took: 0.04s\n",
      "Epoch 19, 50% \t train_loss: 2.79 \t took: 0.05s\n",
      "Epoch 19, 62% \t train_loss: 2.81 \t took: 0.06s\n",
      "Epoch 19, 75% \t train_loss: 2.73 \t took: 0.05s\n",
      "Epoch 19, 87% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 19, 100% \t train_loss: 2.84 \t took: 0.03s\n",
      "Validation loss = 2.13\n",
      "Epoch 20, 12% \t train_loss: 2.61 \t took: 0.09s\n",
      "Epoch 20, 25% \t train_loss: 2.89 \t took: 0.05s\n",
      "Epoch 20, 37% \t train_loss: 2.81 \t took: 0.05s\n",
      "Epoch 20, 50% \t train_loss: 2.66 \t took: 0.06s\n",
      "Epoch 20, 62% \t train_loss: 2.81 \t took: 0.04s\n",
      "Epoch 20, 75% \t train_loss: 2.83 \t took: 0.06s\n",
      "Epoch 20, 87% \t train_loss: 2.77 \t took: 0.04s\n",
      "Epoch 20, 100% \t train_loss: 2.88 \t took: 0.03s\n",
      "Validation loss = 2.14\n",
      "Epoch 21, 12% \t train_loss: 2.76 \t took: 0.10s\n",
      "Epoch 21, 25% \t train_loss: 2.88 \t took: 0.04s\n",
      "Epoch 21, 37% \t train_loss: 2.82 \t took: 0.04s\n",
      "Epoch 21, 50% \t train_loss: 2.67 \t took: 0.06s\n",
      "Epoch 21, 62% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 21, 75% \t train_loss: 2.82 \t took: 0.06s\n",
      "Epoch 21, 87% \t train_loss: 2.77 \t took: 0.04s\n",
      "Epoch 21, 100% \t train_loss: 2.70 \t took: 0.03s\n",
      "Validation loss = 2.12\n",
      "Epoch 22, 12% \t train_loss: 2.83 \t took: 0.10s\n",
      "Epoch 22, 25% \t train_loss: 2.85 \t took: 0.04s\n",
      "Epoch 22, 37% \t train_loss: 2.78 \t took: 0.04s\n",
      "Epoch 22, 50% \t train_loss: 2.71 \t took: 0.05s\n",
      "Epoch 22, 62% \t train_loss: 2.73 \t took: 0.05s\n",
      "Epoch 22, 75% \t train_loss: 2.81 \t took: 0.04s\n",
      "Epoch 22, 87% \t train_loss: 2.75 \t took: 0.06s\n",
      "Epoch 22, 100% \t train_loss: 2.67 \t took: 0.03s\n",
      "Validation loss = 2.13\n",
      "Epoch 23, 12% \t train_loss: 2.66 \t took: 0.10s\n",
      "Epoch 23, 25% \t train_loss: 2.83 \t took: 0.04s\n",
      "Epoch 23, 37% \t train_loss: 2.79 \t took: 0.04s\n",
      "Epoch 23, 50% \t train_loss: 2.85 \t took: 0.06s\n",
      "Epoch 23, 62% \t train_loss: 2.83 \t took: 0.04s\n",
      "Epoch 23, 75% \t train_loss: 2.78 \t took: 0.05s\n",
      "Epoch 23, 87% \t train_loss: 2.79 \t took: 0.04s\n",
      "Epoch 23, 100% \t train_loss: 2.74 \t took: 0.03s\n",
      "Validation loss = 2.13\n",
      "Epoch 24, 12% \t train_loss: 2.73 \t took: 0.09s\n",
      "Epoch 24, 25% \t train_loss: 2.75 \t took: 0.04s\n",
      "Epoch 24, 37% \t train_loss: 2.71 \t took: 0.04s\n",
      "Epoch 24, 50% \t train_loss: 2.81 \t took: 0.05s\n",
      "Epoch 24, 62% \t train_loss: 2.85 \t took: 0.04s\n",
      "Epoch 24, 75% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 24, 87% \t train_loss: 2.80 \t took: 0.05s\n",
      "Epoch 24, 100% \t train_loss: 2.75 \t took: 0.03s\n",
      "Validation loss = 2.12\n",
      "Epoch 25, 12% \t train_loss: 2.68 \t took: 0.10s\n",
      "Epoch 25, 25% \t train_loss: 2.82 \t took: 0.06s\n",
      "Epoch 25, 37% \t train_loss: 2.80 \t took: 0.06s\n",
      "Epoch 25, 50% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 25, 62% \t train_loss: 2.79 \t took: 0.04s\n",
      "Epoch 25, 75% \t train_loss: 2.73 \t took: 0.06s\n",
      "Epoch 25, 87% \t train_loss: 2.80 \t took: 0.04s\n",
      "Epoch 25, 100% \t train_loss: 2.72 \t took: 0.03s\n",
      "Validation loss = 2.11\n",
      "Epoch 26, 12% \t train_loss: 2.78 \t took: 0.10s\n",
      "Epoch 26, 25% \t train_loss: 2.82 \t took: 0.05s\n",
      "Epoch 26, 37% \t train_loss: 2.72 \t took: 0.05s\n",
      "Epoch 26, 50% \t train_loss: 2.82 \t took: 0.06s\n",
      "Epoch 26, 62% \t train_loss: 2.78 \t took: 0.05s\n",
      "Epoch 26, 75% \t train_loss: 2.68 \t took: 0.06s\n",
      "Epoch 26, 87% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 26, 100% \t train_loss: 2.73 \t took: 0.03s\n",
      "Validation loss = 2.11\n",
      "Epoch 27, 12% \t train_loss: 2.69 \t took: 0.10s\n",
      "Epoch 27, 25% \t train_loss: 2.78 \t took: 0.04s\n",
      "Epoch 27, 37% \t train_loss: 2.65 \t took: 0.04s\n",
      "Epoch 27, 50% \t train_loss: 2.92 \t took: 0.05s\n",
      "Epoch 27, 62% \t train_loss: 2.70 \t took: 0.06s\n",
      "Epoch 27, 75% \t train_loss: 2.77 \t took: 0.05s\n",
      "Epoch 27, 87% \t train_loss: 2.67 \t took: 0.05s\n",
      "Epoch 27, 100% \t train_loss: 2.79 \t took: 0.03s\n",
      "Validation loss = 2.11\n",
      "Epoch 28, 12% \t train_loss: 2.89 \t took: 0.10s\n",
      "Epoch 28, 25% \t train_loss: 2.81 \t took: 0.05s\n",
      "Epoch 28, 37% \t train_loss: 2.65 \t took: 0.05s\n",
      "Epoch 28, 50% \t train_loss: 2.68 \t took: 0.06s\n",
      "Epoch 28, 62% \t train_loss: 2.82 \t took: 0.04s\n",
      "Epoch 28, 75% \t train_loss: 2.68 \t took: 0.06s\n",
      "Epoch 28, 87% \t train_loss: 2.68 \t took: 0.04s\n",
      "Epoch 28, 100% \t train_loss: 2.77 \t took: 0.03s\n",
      "Validation loss = 2.11\n",
      "Epoch 29, 12% \t train_loss: 2.73 \t took: 0.09s\n",
      "Epoch 29, 25% \t train_loss: 2.78 \t took: 0.05s\n",
      "Epoch 29, 37% \t train_loss: 2.76 \t took: 0.04s\n",
      "Epoch 29, 50% \t train_loss: 2.77 \t took: 0.06s\n",
      "Epoch 29, 62% \t train_loss: 2.69 \t took: 0.05s\n",
      "Epoch 29, 75% \t train_loss: 2.76 \t took: 0.06s\n",
      "Epoch 29, 87% \t train_loss: 2.76 \t took: 0.04s\n",
      "Epoch 29, 100% \t train_loss: 2.83 \t took: 0.03s\n",
      "Validation loss = 2.10\n",
      "Epoch 30, 12% \t train_loss: 2.82 \t took: 0.10s\n",
      "Epoch 30, 25% \t train_loss: 2.85 \t took: 0.05s\n",
      "Epoch 30, 37% \t train_loss: 2.64 \t took: 0.05s\n",
      "Epoch 30, 50% \t train_loss: 2.69 \t took: 0.06s\n",
      "Epoch 30, 62% \t train_loss: 2.70 \t took: 0.05s\n",
      "Epoch 30, 75% \t train_loss: 2.80 \t took: 0.06s\n",
      "Epoch 30, 87% \t train_loss: 2.80 \t took: 0.04s\n",
      "Epoch 30, 100% \t train_loss: 2.79 \t took: 0.03s\n",
      "Validation loss = 2.11\n",
      "Epoch 31, 12% \t train_loss: 2.75 \t took: 0.09s\n",
      "Epoch 31, 25% \t train_loss: 2.72 \t took: 0.04s\n",
      "Epoch 31, 37% \t train_loss: 2.84 \t took: 0.04s\n",
      "Epoch 31, 50% \t train_loss: 2.78 \t took: 0.04s\n",
      "Epoch 31, 62% \t train_loss: 2.62 \t took: 0.05s\n",
      "Epoch 31, 75% \t train_loss: 2.83 \t took: 0.05s\n",
      "Epoch 31, 87% \t train_loss: 2.77 \t took: 0.05s\n",
      "Epoch 31, 100% \t train_loss: 2.65 \t took: 0.03s\n",
      "Validation loss = 2.12\n",
      "Epoch 32, 12% \t train_loss: 2.70 \t took: 0.10s\n",
      "Epoch 32, 25% \t train_loss: 2.67 \t took: 0.04s\n",
      "Epoch 32, 37% \t train_loss: 2.68 \t took: 0.05s\n",
      "Epoch 32, 50% \t train_loss: 2.74 \t took: 0.06s\n",
      "Epoch 32, 62% \t train_loss: 2.85 \t took: 0.04s\n",
      "Epoch 32, 75% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 32, 87% \t train_loss: 2.75 \t took: 0.05s\n",
      "Epoch 32, 100% \t train_loss: 2.66 \t took: 0.03s\n",
      "Validation loss = 2.11\n",
      "Epoch 33, 12% \t train_loss: 2.59 \t took: 0.09s\n",
      "Epoch 33, 25% \t train_loss: 2.69 \t took: 0.04s\n",
      "Epoch 33, 37% \t train_loss: 2.83 \t took: 0.04s\n",
      "Epoch 33, 50% \t train_loss: 2.59 \t took: 0.04s\n",
      "Epoch 33, 62% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 33, 75% \t train_loss: 2.81 \t took: 0.04s\n",
      "Epoch 33, 87% \t train_loss: 2.87 \t took: 0.05s\n",
      "Epoch 33, 100% \t train_loss: 2.75 \t took: 0.03s\n",
      "Validation loss = 2.12\n",
      "Epoch 34, 12% \t train_loss: 2.80 \t took: 0.10s\n",
      "Epoch 34, 25% \t train_loss: 2.68 \t took: 0.05s\n",
      "Epoch 34, 37% \t train_loss: 2.66 \t took: 0.05s\n",
      "Epoch 34, 50% \t train_loss: 2.66 \t took: 0.06s\n",
      "Epoch 34, 62% \t train_loss: 2.80 \t took: 0.05s\n",
      "Epoch 34, 75% \t train_loss: 2.70 \t took: 0.06s\n",
      "Epoch 34, 87% \t train_loss: 2.82 \t took: 0.04s\n",
      "Epoch 34, 100% \t train_loss: 2.72 \t took: 0.03s\n",
      "Validation loss = 2.10\n",
      "Epoch 35, 12% \t train_loss: 2.69 \t took: 0.09s\n",
      "Epoch 35, 25% \t train_loss: 2.85 \t took: 0.05s\n",
      "Epoch 35, 37% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 35, 50% \t train_loss: 2.79 \t took: 0.06s\n",
      "Epoch 35, 62% \t train_loss: 2.66 \t took: 0.05s\n",
      "Epoch 35, 75% \t train_loss: 2.80 \t took: 0.06s\n",
      "Epoch 35, 87% \t train_loss: 2.72 \t took: 0.05s\n",
      "Epoch 35, 100% \t train_loss: 2.65 \t took: 0.03s\n",
      "Validation loss = 2.09\n",
      "Epoch 36, 12% \t train_loss: 2.68 \t took: 0.20s\n",
      "Epoch 36, 25% \t train_loss: 2.72 \t took: 0.13s\n",
      "Epoch 36, 37% \t train_loss: 2.77 \t took: 0.05s\n",
      "Epoch 36, 50% \t train_loss: 2.71 \t took: 0.04s\n",
      "Epoch 36, 62% \t train_loss: 2.75 \t took: 0.07s\n",
      "Epoch 36, 75% \t train_loss: 2.72 \t took: 0.08s\n",
      "Epoch 36, 87% \t train_loss: 2.81 \t took: 0.10s\n",
      "Epoch 36, 100% \t train_loss: 2.61 \t took: 0.07s\n",
      "Validation loss = 2.09\n",
      "Epoch 37, 12% \t train_loss: 2.64 \t took: 0.10s\n",
      "Epoch 37, 25% \t train_loss: 2.77 \t took: 0.05s\n",
      "Epoch 37, 37% \t train_loss: 2.68 \t took: 0.05s\n",
      "Epoch 37, 50% \t train_loss: 2.58 \t took: 0.10s\n",
      "Epoch 37, 62% \t train_loss: 2.72 \t took: 0.08s\n",
      "Epoch 37, 75% \t train_loss: 2.65 \t took: 0.04s\n",
      "Epoch 37, 87% \t train_loss: 2.87 \t took: 0.04s\n",
      "Epoch 37, 100% \t train_loss: 2.86 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 38, 12% \t train_loss: 2.76 \t took: 0.10s\n",
      "Epoch 38, 25% \t train_loss: 2.77 \t took: 0.04s\n",
      "Epoch 38, 37% \t train_loss: 2.72 \t took: 0.04s\n",
      "Epoch 38, 50% \t train_loss: 2.70 \t took: 0.04s\n",
      "Epoch 38, 62% \t train_loss: 2.73 \t took: 0.08s\n",
      "Epoch 38, 75% \t train_loss: 2.74 \t took: 0.06s\n",
      "Epoch 38, 87% \t train_loss: 2.58 \t took: 0.09s\n",
      "Epoch 38, 100% \t train_loss: 2.78 \t took: 0.07s\n",
      "Validation loss = 2.10\n",
      "Epoch 39, 12% \t train_loss: 2.75 \t took: 0.14s\n",
      "Epoch 39, 25% \t train_loss: 2.56 \t took: 0.06s\n",
      "Epoch 39, 37% \t train_loss: 2.74 \t took: 0.08s\n",
      "Epoch 39, 50% \t train_loss: 2.80 \t took: 0.06s\n",
      "Epoch 39, 62% \t train_loss: 2.80 \t took: 0.08s\n",
      "Epoch 39, 75% \t train_loss: 2.76 \t took: 0.08s\n",
      "Epoch 39, 87% \t train_loss: 2.58 \t took: 0.07s\n",
      "Epoch 39, 100% \t train_loss: 2.79 \t took: 0.06s\n",
      "Validation loss = 2.10\n",
      "Epoch 40, 12% \t train_loss: 2.62 \t took: 0.10s\n",
      "Epoch 40, 25% \t train_loss: 2.60 \t took: 0.05s\n",
      "Epoch 40, 37% \t train_loss: 2.76 \t took: 0.04s\n",
      "Epoch 40, 50% \t train_loss: 2.72 \t took: 0.07s\n",
      "Epoch 40, 62% \t train_loss: 2.70 \t took: 0.09s\n",
      "Epoch 40, 75% \t train_loss: 2.77 \t took: 0.04s\n",
      "Epoch 40, 87% \t train_loss: 2.74 \t took: 0.04s\n",
      "Epoch 40, 100% \t train_loss: 2.81 \t took: 0.04s\n",
      "Validation loss = 2.09\n",
      "Epoch 41, 12% \t train_loss: 2.63 \t took: 0.11s\n",
      "Epoch 41, 25% \t train_loss: 2.88 \t took: 0.05s\n",
      "Epoch 41, 37% \t train_loss: 2.66 \t took: 0.07s\n",
      "Epoch 41, 50% \t train_loss: 2.68 \t took: 0.05s\n",
      "Epoch 41, 62% \t train_loss: 2.68 \t took: 0.05s\n",
      "Epoch 41, 75% \t train_loss: 2.61 \t took: 0.06s\n",
      "Epoch 41, 87% \t train_loss: 2.75 \t took: 0.05s\n",
      "Epoch 41, 100% \t train_loss: 2.77 \t took: 0.04s\n",
      "Validation loss = 2.09\n",
      "Epoch 42, 12% \t train_loss: 2.73 \t took: 0.09s\n",
      "Epoch 42, 25% \t train_loss: 2.64 \t took: 0.04s\n",
      "Epoch 42, 37% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 42, 50% \t train_loss: 2.60 \t took: 0.05s\n",
      "Epoch 42, 62% \t train_loss: 2.71 \t took: 0.06s\n",
      "Epoch 42, 75% \t train_loss: 2.69 \t took: 0.06s\n",
      "Epoch 42, 87% \t train_loss: 2.75 \t took: 0.05s\n",
      "Epoch 42, 100% \t train_loss: 2.67 \t took: 0.04s\n",
      "Validation loss = 2.08\n",
      "Epoch 43, 12% \t train_loss: 2.73 \t took: 0.10s\n",
      "Epoch 43, 25% \t train_loss: 2.70 \t took: 0.05s\n",
      "Epoch 43, 37% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 43, 50% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 43, 62% \t train_loss: 2.69 \t took: 0.06s\n",
      "Epoch 43, 75% \t train_loss: 2.61 \t took: 0.06s\n",
      "Epoch 43, 87% \t train_loss: 2.68 \t took: 0.04s\n",
      "Epoch 43, 100% \t train_loss: 2.77 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 44, 12% \t train_loss: 2.74 \t took: 0.10s\n",
      "Epoch 44, 25% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 44, 37% \t train_loss: 2.71 \t took: 0.07s\n",
      "Epoch 44, 50% \t train_loss: 2.73 \t took: 0.06s\n",
      "Epoch 44, 62% \t train_loss: 2.65 \t took: 0.08s\n",
      "Epoch 44, 75% \t train_loss: 2.63 \t took: 0.04s\n",
      "Epoch 44, 87% \t train_loss: 2.65 \t took: 0.04s\n",
      "Epoch 44, 100% \t train_loss: 2.77 \t took: 0.04s\n",
      "Validation loss = 2.07\n",
      "Epoch 45, 12% \t train_loss: 2.66 \t took: 0.11s\n",
      "Epoch 45, 25% \t train_loss: 2.72 \t took: 0.05s\n",
      "Epoch 45, 37% \t train_loss: 2.69 \t took: 0.05s\n",
      "Epoch 45, 50% \t train_loss: 2.58 \t took: 0.07s\n",
      "Epoch 45, 62% \t train_loss: 2.68 \t took: 0.08s\n",
      "Epoch 45, 75% \t train_loss: 2.80 \t took: 0.06s\n",
      "Epoch 45, 87% \t train_loss: 2.71 \t took: 0.07s\n",
      "Epoch 45, 100% \t train_loss: 2.79 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 46, 12% \t train_loss: 2.74 \t took: 0.10s\n",
      "Epoch 46, 25% \t train_loss: 2.49 \t took: 0.04s\n",
      "Epoch 46, 37% \t train_loss: 2.77 \t took: 0.04s\n",
      "Epoch 46, 50% \t train_loss: 2.57 \t took: 0.06s\n",
      "Epoch 46, 62% \t train_loss: 2.76 \t took: 0.04s\n",
      "Epoch 46, 75% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 46, 87% \t train_loss: 2.70 \t took: 0.06s\n",
      "Epoch 46, 100% \t train_loss: 2.74 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 47, 12% \t train_loss: 2.62 \t took: 0.10s\n",
      "Epoch 47, 25% \t train_loss: 2.63 \t took: 0.06s\n",
      "Epoch 47, 37% \t train_loss: 2.67 \t took: 0.04s\n",
      "Epoch 47, 50% \t train_loss: 2.67 \t took: 0.07s\n",
      "Epoch 47, 62% \t train_loss: 2.84 \t took: 0.05s\n",
      "Epoch 47, 75% \t train_loss: 2.73 \t took: 0.06s\n",
      "Epoch 47, 87% \t train_loss: 2.62 \t took: 0.05s\n",
      "Epoch 47, 100% \t train_loss: 2.84 \t took: 0.04s\n",
      "Validation loss = 2.09\n",
      "Epoch 48, 12% \t train_loss: 2.70 \t took: 0.11s\n",
      "Epoch 48, 25% \t train_loss: 2.54 \t took: 0.05s\n",
      "Epoch 48, 37% \t train_loss: 2.73 \t took: 0.05s\n",
      "Epoch 48, 50% \t train_loss: 2.71 \t took: 0.06s\n",
      "Epoch 48, 62% \t train_loss: 2.58 \t took: 0.04s\n",
      "Epoch 48, 75% \t train_loss: 2.75 \t took: 0.07s\n",
      "Epoch 48, 87% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 48, 100% \t train_loss: 2.80 \t took: 0.03s\n",
      "Validation loss = 2.07\n",
      "Epoch 49, 12% \t train_loss: 2.63 \t took: 0.13s\n",
      "Epoch 49, 25% \t train_loss: 2.70 \t took: 0.11s\n",
      "Epoch 49, 37% \t train_loss: 2.64 \t took: 0.10s\n",
      "Epoch 49, 50% \t train_loss: 2.67 \t took: 0.10s\n",
      "Epoch 49, 62% \t train_loss: 2.75 \t took: 0.07s\n",
      "Epoch 49, 75% \t train_loss: 2.60 \t took: 0.07s\n",
      "Epoch 49, 87% \t train_loss: 2.67 \t took: 0.04s\n",
      "Epoch 49, 100% \t train_loss: 2.66 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 50, 12% \t train_loss: 2.66 \t took: 0.10s\n",
      "Epoch 50, 25% \t train_loss: 2.69 \t took: 0.04s\n",
      "Epoch 50, 37% \t train_loss: 2.77 \t took: 0.04s\n",
      "Epoch 50, 50% \t train_loss: 2.61 \t took: 0.08s\n",
      "Epoch 50, 62% \t train_loss: 2.81 \t took: 0.06s\n",
      "Epoch 50, 75% \t train_loss: 2.67 \t took: 0.06s\n",
      "Epoch 50, 87% \t train_loss: 2.70 \t took: 0.04s\n",
      "Epoch 50, 100% \t train_loss: 2.50 \t took: 0.03s\n",
      "Validation loss = 2.07\n",
      "Epoch 51, 12% \t train_loss: 2.63 \t took: 0.10s\n",
      "Epoch 51, 25% \t train_loss: 2.66 \t took: 0.04s\n",
      "Epoch 51, 37% \t train_loss: 2.64 \t took: 0.04s\n",
      "Epoch 51, 50% \t train_loss: 2.79 \t took: 0.05s\n",
      "Epoch 51, 62% \t train_loss: 2.69 \t took: 0.06s\n",
      "Epoch 51, 75% \t train_loss: 2.57 \t took: 0.07s\n",
      "Epoch 51, 87% \t train_loss: 2.69 \t took: 0.04s\n",
      "Epoch 51, 100% \t train_loss: 2.75 \t took: 0.03s\n",
      "Validation loss = 2.09\n",
      "Epoch 52, 12% \t train_loss: 2.51 \t took: 0.10s\n",
      "Epoch 52, 25% \t train_loss: 2.78 \t took: 0.05s\n",
      "Epoch 52, 37% \t train_loss: 2.71 \t took: 0.05s\n",
      "Epoch 52, 50% \t train_loss: 2.60 \t took: 0.07s\n",
      "Epoch 52, 62% \t train_loss: 2.82 \t took: 0.06s\n",
      "Epoch 52, 75% \t train_loss: 2.71 \t took: 0.07s\n",
      "Epoch 52, 87% \t train_loss: 2.58 \t took: 0.05s\n",
      "Epoch 52, 100% \t train_loss: 2.87 \t took: 0.04s\n",
      "Validation loss = 2.06\n",
      "Epoch 53, 12% \t train_loss: 2.59 \t took: 0.10s\n",
      "Epoch 53, 25% \t train_loss: 2.66 \t took: 0.04s\n",
      "Epoch 53, 37% \t train_loss: 2.65 \t took: 0.04s\n",
      "Epoch 53, 50% \t train_loss: 2.77 \t took: 0.06s\n",
      "Epoch 53, 62% \t train_loss: 2.63 \t took: 0.08s\n",
      "Epoch 53, 75% \t train_loss: 2.62 \t took: 0.06s\n",
      "Epoch 53, 87% \t train_loss: 2.77 \t took: 0.04s\n",
      "Epoch 53, 100% \t train_loss: 2.75 \t took: 0.04s\n",
      "Validation loss = 2.07\n",
      "Epoch 54, 12% \t train_loss: 2.64 \t took: 0.17s\n",
      "Epoch 54, 25% \t train_loss: 2.59 \t took: 0.07s\n",
      "Epoch 54, 37% \t train_loss: 2.50 \t took: 0.06s\n",
      "Epoch 54, 50% \t train_loss: 2.77 \t took: 0.05s\n",
      "Epoch 54, 62% \t train_loss: 2.75 \t took: 0.08s\n",
      "Epoch 54, 75% \t train_loss: 2.70 \t took: 0.08s\n",
      "Epoch 54, 87% \t train_loss: 2.70 \t took: 0.04s\n",
      "Epoch 54, 100% \t train_loss: 2.88 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 55, 12% \t train_loss: 2.71 \t took: 0.11s\n",
      "Epoch 55, 25% \t train_loss: 2.67 \t took: 0.11s\n",
      "Epoch 55, 37% \t train_loss: 2.77 \t took: 0.12s\n",
      "Epoch 55, 50% \t train_loss: 2.60 \t took: 0.12s\n",
      "Epoch 55, 62% \t train_loss: 2.80 \t took: 0.08s\n",
      "Epoch 55, 75% \t train_loss: 2.58 \t took: 0.07s\n",
      "Epoch 55, 87% \t train_loss: 2.64 \t took: 0.04s\n",
      "Epoch 55, 100% \t train_loss: 2.46 \t took: 0.04s\n",
      "Validation loss = 2.08\n",
      "Epoch 56, 12% \t train_loss: 2.71 \t took: 0.10s\n",
      "Epoch 56, 25% \t train_loss: 2.60 \t took: 0.04s\n",
      "Epoch 56, 37% \t train_loss: 2.72 \t took: 0.05s\n",
      "Epoch 56, 50% \t train_loss: 2.59 \t took: 0.05s\n",
      "Epoch 56, 62% \t train_loss: 2.72 \t took: 0.05s\n",
      "Epoch 56, 75% \t train_loss: 2.70 \t took: 0.06s\n",
      "Epoch 56, 87% \t train_loss: 2.71 \t took: 0.04s\n",
      "Epoch 56, 100% \t train_loss: 2.67 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 57, 12% \t train_loss: 2.64 \t took: 0.10s\n",
      "Epoch 57, 25% \t train_loss: 2.64 \t took: 0.04s\n",
      "Epoch 57, 37% \t train_loss: 2.61 \t took: 0.04s\n",
      "Epoch 57, 50% \t train_loss: 2.76 \t took: 0.05s\n",
      "Epoch 57, 62% \t train_loss: 2.62 \t took: 0.06s\n",
      "Epoch 57, 75% \t train_loss: 2.71 \t took: 0.06s\n",
      "Epoch 57, 87% \t train_loss: 2.76 \t took: 0.04s\n",
      "Epoch 57, 100% \t train_loss: 2.52 \t took: 0.03s\n",
      "Validation loss = 2.05\n",
      "Epoch 58, 12% \t train_loss: 2.58 \t took: 0.10s\n",
      "Epoch 58, 25% \t train_loss: 2.83 \t took: 0.04s\n",
      "Epoch 58, 37% \t train_loss: 2.61 \t took: 0.05s\n",
      "Epoch 58, 50% \t train_loss: 2.79 \t took: 0.07s\n",
      "Epoch 58, 62% \t train_loss: 2.65 \t took: 0.06s\n",
      "Epoch 58, 75% \t train_loss: 2.62 \t took: 0.06s\n",
      "Epoch 58, 87% \t train_loss: 2.69 \t took: 0.04s\n",
      "Epoch 58, 100% \t train_loss: 2.57 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 59, 12% \t train_loss: 2.72 \t took: 0.13s\n",
      "Epoch 59, 25% \t train_loss: 2.62 \t took: 0.04s\n",
      "Epoch 59, 37% \t train_loss: 2.68 \t took: 0.06s\n",
      "Epoch 59, 50% \t train_loss: 2.79 \t took: 0.06s\n",
      "Epoch 59, 62% \t train_loss: 2.59 \t took: 0.07s\n",
      "Epoch 59, 75% \t train_loss: 2.65 \t took: 0.14s\n",
      "Epoch 59, 87% \t train_loss: 2.53 \t took: 0.12s\n",
      "Epoch 59, 100% \t train_loss: 2.60 \t took: 0.05s\n",
      "Validation loss = 2.06\n",
      "Epoch 60, 12% \t train_loss: 2.47 \t took: 0.10s\n",
      "Epoch 60, 25% \t train_loss: 2.68 \t took: 0.04s\n",
      "Epoch 60, 37% \t train_loss: 2.66 \t took: 0.04s\n",
      "Epoch 60, 50% \t train_loss: 2.89 \t took: 0.06s\n",
      "Epoch 60, 62% \t train_loss: 2.56 \t took: 0.11s\n",
      "Epoch 60, 75% \t train_loss: 2.72 \t took: 0.11s\n",
      "Epoch 60, 87% \t train_loss: 2.65 \t took: 0.11s\n",
      "Epoch 60, 100% \t train_loss: 2.73 \t took: 0.05s\n",
      "Validation loss = 2.07\n",
      "Epoch 61, 12% \t train_loss: 2.53 \t took: 0.13s\n",
      "Epoch 61, 25% \t train_loss: 2.59 \t took: 0.08s\n",
      "Epoch 61, 37% \t train_loss: 2.77 \t took: 0.07s\n",
      "Epoch 61, 50% \t train_loss: 2.61 \t took: 0.08s\n",
      "Epoch 61, 62% \t train_loss: 2.76 \t took: 0.10s\n",
      "Epoch 61, 75% \t train_loss: 2.71 \t took: 0.06s\n",
      "Epoch 61, 87% \t train_loss: 2.57 \t took: 0.05s\n",
      "Epoch 61, 100% \t train_loss: 2.72 \t took: 0.06s\n",
      "Validation loss = 2.06\n",
      "Epoch 62, 12% \t train_loss: 2.54 \t took: 0.11s\n",
      "Epoch 62, 25% \t train_loss: 2.71 \t took: 0.04s\n",
      "Epoch 62, 37% \t train_loss: 2.54 \t took: 0.05s\n",
      "Epoch 62, 50% \t train_loss: 2.71 \t took: 0.07s\n",
      "Epoch 62, 62% \t train_loss: 2.71 \t took: 0.05s\n",
      "Epoch 62, 75% \t train_loss: 2.66 \t took: 0.07s\n",
      "Epoch 62, 87% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 62, 100% \t train_loss: 2.57 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 63, 12% \t train_loss: 2.61 \t took: 0.10s\n",
      "Epoch 63, 25% \t train_loss: 2.68 \t took: 0.04s\n",
      "Epoch 63, 37% \t train_loss: 2.68 \t took: 0.04s\n",
      "Epoch 63, 50% \t train_loss: 2.57 \t took: 0.05s\n",
      "Epoch 63, 62% \t train_loss: 2.59 \t took: 0.07s\n",
      "Epoch 63, 75% \t train_loss: 2.66 \t took: 0.08s\n",
      "Epoch 63, 87% \t train_loss: 2.79 \t took: 0.05s\n",
      "Epoch 63, 100% \t train_loss: 2.67 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 64, 12% \t train_loss: 2.64 \t took: 0.13s\n",
      "Epoch 64, 25% \t train_loss: 2.64 \t took: 0.11s\n",
      "Epoch 64, 37% \t train_loss: 2.67 \t took: 0.11s\n",
      "Epoch 64, 50% \t train_loss: 2.76 \t took: 0.09s\n",
      "Epoch 64, 62% \t train_loss: 2.68 \t took: 0.08s\n",
      "Epoch 64, 75% \t train_loss: 2.55 \t took: 0.08s\n",
      "Epoch 64, 87% \t train_loss: 2.61 \t took: 0.06s\n",
      "Epoch 64, 100% \t train_loss: 2.55 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 65, 12% \t train_loss: 2.68 \t took: 0.14s\n",
      "Epoch 65, 25% \t train_loss: 2.57 \t took: 0.05s\n",
      "Epoch 65, 37% \t train_loss: 2.59 \t took: 0.07s\n",
      "Epoch 65, 50% \t train_loss: 2.77 \t took: 0.05s\n",
      "Epoch 65, 62% \t train_loss: 2.73 \t took: 0.06s\n",
      "Epoch 65, 75% \t train_loss: 2.48 \t took: 0.06s\n",
      "Epoch 65, 87% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 65, 100% \t train_loss: 2.75 \t took: 0.04s\n",
      "Validation loss = 2.06\n",
      "Epoch 66, 12% \t train_loss: 2.64 \t took: 0.12s\n",
      "Epoch 66, 25% \t train_loss: 2.59 \t took: 0.05s\n",
      "Epoch 66, 37% \t train_loss: 2.67 \t took: 0.06s\n",
      "Epoch 66, 50% \t train_loss: 2.60 \t took: 0.07s\n",
      "Epoch 66, 62% \t train_loss: 2.65 \t took: 0.05s\n",
      "Epoch 66, 75% \t train_loss: 2.65 \t took: 0.06s\n",
      "Epoch 66, 87% \t train_loss: 2.74 \t took: 0.05s\n",
      "Epoch 66, 100% \t train_loss: 2.51 \t took: 0.05s\n",
      "Validation loss = 2.06\n",
      "Epoch 67, 12% \t train_loss: 2.65 \t took: 0.10s\n",
      "Epoch 67, 25% \t train_loss: 2.64 \t took: 0.04s\n",
      "Epoch 67, 37% \t train_loss: 2.66 \t took: 0.08s\n",
      "Epoch 67, 50% \t train_loss: 2.58 \t took: 0.11s\n",
      "Epoch 67, 62% \t train_loss: 2.54 \t took: 0.11s\n",
      "Epoch 67, 75% \t train_loss: 2.69 \t took: 0.08s\n",
      "Epoch 67, 87% \t train_loss: 2.77 \t took: 0.09s\n",
      "Epoch 67, 100% \t train_loss: 2.69 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 68, 12% \t train_loss: 2.44 \t took: 0.14s\n",
      "Epoch 68, 25% \t train_loss: 2.74 \t took: 0.04s\n",
      "Epoch 68, 37% \t train_loss: 2.76 \t took: 0.06s\n",
      "Epoch 68, 50% \t train_loss: 2.65 \t took: 0.05s\n",
      "Epoch 68, 62% \t train_loss: 2.67 \t took: 0.04s\n",
      "Epoch 68, 75% \t train_loss: 2.69 \t took: 0.06s\n",
      "Epoch 68, 87% \t train_loss: 2.63 \t took: 0.05s\n",
      "Epoch 68, 100% \t train_loss: 2.65 \t took: 0.04s\n",
      "Validation loss = 2.05\n",
      "Epoch 69, 12% \t train_loss: 2.60 \t took: 0.11s\n",
      "Epoch 69, 25% \t train_loss: 2.67 \t took: 0.09s\n",
      "Epoch 69, 37% \t train_loss: 2.70 \t took: 0.13s\n",
      "Epoch 69, 50% \t train_loss: 2.74 \t took: 0.11s\n",
      "Epoch 69, 62% \t train_loss: 2.67 \t took: 0.06s\n",
      "Epoch 69, 75% \t train_loss: 2.54 \t took: 0.07s\n",
      "Epoch 69, 87% \t train_loss: 2.76 \t took: 0.06s\n",
      "Epoch 69, 100% \t train_loss: 2.47 \t took: 0.04s\n",
      "Validation loss = 2.06\n",
      "Epoch 70, 12% \t train_loss: 2.53 \t took: 0.12s\n",
      "Epoch 70, 25% \t train_loss: 2.78 \t took: 0.05s\n",
      "Epoch 70, 37% \t train_loss: 2.66 \t took: 0.06s\n",
      "Epoch 70, 50% \t train_loss: 2.49 \t took: 0.06s\n",
      "Epoch 70, 62% \t train_loss: 2.66 \t took: 0.07s\n",
      "Epoch 70, 75% \t train_loss: 2.78 \t took: 0.07s\n",
      "Epoch 70, 87% \t train_loss: 2.73 \t took: 0.06s\n",
      "Epoch 70, 100% \t train_loss: 2.62 \t took: 0.04s\n",
      "Validation loss = 2.04\n",
      "Epoch 71, 12% \t train_loss: 2.60 \t took: 0.10s\n",
      "Epoch 71, 25% \t train_loss: 2.61 \t took: 0.04s\n",
      "Epoch 71, 37% \t train_loss: 2.80 \t took: 0.04s\n",
      "Epoch 71, 50% \t train_loss: 2.47 \t took: 0.04s\n",
      "Epoch 71, 62% \t train_loss: 2.70 \t took: 0.06s\n",
      "Epoch 71, 75% \t train_loss: 2.58 \t took: 0.11s\n",
      "Epoch 71, 87% \t train_loss: 2.68 \t took: 0.09s\n",
      "Epoch 71, 100% \t train_loss: 2.59 \t took: 0.07s\n",
      "Validation loss = 2.05\n",
      "Epoch 72, 12% \t train_loss: 2.68 \t took: 0.11s\n",
      "Epoch 72, 25% \t train_loss: 2.70 \t took: 0.04s\n",
      "Epoch 72, 37% \t train_loss: 2.48 \t took: 0.04s\n",
      "Epoch 72, 50% \t train_loss: 2.48 \t took: 0.06s\n",
      "Epoch 72, 62% \t train_loss: 2.61 \t took: 0.11s\n",
      "Epoch 72, 75% \t train_loss: 2.74 \t took: 0.11s\n",
      "Epoch 72, 87% \t train_loss: 2.79 \t took: 0.07s\n",
      "Epoch 72, 100% \t train_loss: 2.61 \t took: 0.07s\n",
      "Validation loss = 2.05\n",
      "Epoch 73, 12% \t train_loss: 2.64 \t took: 0.11s\n",
      "Epoch 73, 25% \t train_loss: 2.59 \t took: 0.13s\n",
      "Epoch 73, 37% \t train_loss: 2.78 \t took: 0.12s\n",
      "Epoch 73, 50% \t train_loss: 2.52 \t took: 0.10s\n",
      "Epoch 73, 62% \t train_loss: 2.69 \t took: 0.08s\n",
      "Epoch 73, 75% \t train_loss: 2.67 \t took: 0.07s\n",
      "Epoch 73, 87% \t train_loss: 2.59 \t took: 0.15s\n",
      "Epoch 73, 100% \t train_loss: 2.56 \t took: 0.06s\n",
      "Validation loss = 2.05\n",
      "Epoch 74, 12% \t train_loss: 2.60 \t took: 0.12s\n",
      "Epoch 74, 25% \t train_loss: 2.61 \t took: 0.09s\n",
      "Epoch 74, 37% \t train_loss: 2.53 \t took: 0.13s\n",
      "Epoch 74, 50% \t train_loss: 2.63 \t took: 0.08s\n",
      "Epoch 74, 62% \t train_loss: 2.81 \t took: 0.08s\n",
      "Epoch 74, 75% \t train_loss: 2.75 \t took: 0.08s\n",
      "Epoch 74, 87% \t train_loss: 2.64 \t took: 0.12s\n",
      "Epoch 74, 100% \t train_loss: 2.61 \t took: 0.04s\n",
      "Validation loss = 2.06\n",
      "Epoch 75, 12% \t train_loss: 2.58 \t took: 0.10s\n",
      "Epoch 75, 25% \t train_loss: 2.76 \t took: 0.04s\n",
      "Epoch 75, 37% \t train_loss: 2.60 \t took: 0.05s\n",
      "Epoch 75, 50% \t train_loss: 2.62 \t took: 0.06s\n",
      "Epoch 75, 62% \t train_loss: 2.58 \t took: 0.05s\n",
      "Epoch 75, 75% \t train_loss: 2.52 \t took: 0.07s\n",
      "Epoch 75, 87% \t train_loss: 2.65 \t took: 0.12s\n",
      "Epoch 75, 100% \t train_loss: 2.81 \t took: 0.08s\n",
      "Validation loss = 2.05\n",
      "Epoch 76, 12% \t train_loss: 2.62 \t took: 0.12s\n",
      "Epoch 76, 25% \t train_loss: 2.69 \t took: 0.11s\n",
      "Epoch 76, 37% \t train_loss: 2.60 \t took: 0.15s\n",
      "Epoch 76, 50% \t train_loss: 2.54 \t took: 0.12s\n",
      "Epoch 76, 62% \t train_loss: 2.60 \t took: 0.07s\n",
      "Epoch 76, 75% \t train_loss: 2.52 \t took: 0.06s\n",
      "Epoch 76, 87% \t train_loss: 2.76 \t took: 0.07s\n",
      "Epoch 76, 100% \t train_loss: 2.65 \t took: 0.04s\n",
      "Validation loss = 2.05\n",
      "Epoch 77, 12% \t train_loss: 2.67 \t took: 0.10s\n",
      "Epoch 77, 25% \t train_loss: 2.71 \t took: 0.04s\n",
      "Epoch 77, 37% \t train_loss: 2.58 \t took: 0.04s\n",
      "Epoch 77, 50% \t train_loss: 2.61 \t took: 0.05s\n",
      "Epoch 77, 62% \t train_loss: 2.72 \t took: 0.06s\n",
      "Epoch 77, 75% \t train_loss: 2.56 \t took: 0.05s\n",
      "Epoch 77, 87% \t train_loss: 2.50 \t took: 0.07s\n",
      "Epoch 77, 100% \t train_loss: 2.62 \t took: 0.04s\n",
      "Validation loss = 2.07\n",
      "Epoch 78, 12% \t train_loss: 2.76 \t took: 0.10s\n",
      "Epoch 78, 25% \t train_loss: 2.68 \t took: 0.05s\n",
      "Epoch 78, 37% \t train_loss: 2.50 \t took: 0.04s\n",
      "Epoch 78, 50% \t train_loss: 2.38 \t took: 0.04s\n",
      "Epoch 78, 62% \t train_loss: 2.82 \t took: 0.06s\n",
      "Epoch 78, 75% \t train_loss: 2.64 \t took: 0.07s\n",
      "Epoch 78, 87% \t train_loss: 2.74 \t took: 0.05s\n",
      "Epoch 78, 100% \t train_loss: 2.61 \t took: 0.03s\n",
      "Validation loss = 2.04\n",
      "Epoch 79, 12% \t train_loss: 2.58 \t took: 0.10s\n",
      "Epoch 79, 25% \t train_loss: 2.64 \t took: 0.04s\n",
      "Epoch 79, 37% \t train_loss: 2.74 \t took: 0.04s\n",
      "Epoch 79, 50% \t train_loss: 2.58 \t took: 0.04s\n",
      "Epoch 79, 62% \t train_loss: 2.73 \t took: 0.07s\n",
      "Epoch 79, 75% \t train_loss: 2.57 \t took: 0.05s\n",
      "Epoch 79, 87% \t train_loss: 2.51 \t took: 0.06s\n",
      "Epoch 79, 100% \t train_loss: 2.71 \t took: 0.04s\n",
      "Validation loss = 2.04\n",
      "Epoch 80, 12% \t train_loss: 2.69 \t took: 0.10s\n",
      "Epoch 80, 25% \t train_loss: 2.58 \t took: 0.04s\n",
      "Epoch 80, 37% \t train_loss: 2.84 \t took: 0.04s\n",
      "Epoch 80, 50% \t train_loss: 2.55 \t took: 0.06s\n",
      "Epoch 80, 62% \t train_loss: 2.57 \t took: 0.06s\n",
      "Epoch 80, 75% \t train_loss: 2.56 \t took: 0.08s\n",
      "Epoch 80, 87% \t train_loss: 2.51 \t took: 0.06s\n",
      "Epoch 80, 100% \t train_loss: 2.66 \t took: 0.07s\n",
      "Validation loss = 2.05\n",
      "Epoch 81, 12% \t train_loss: 2.49 \t took: 0.10s\n",
      "Epoch 81, 25% \t train_loss: 2.72 \t took: 0.05s\n",
      "Epoch 81, 37% \t train_loss: 2.70 \t took: 0.05s\n",
      "Epoch 81, 50% \t train_loss: 2.60 \t took: 0.06s\n",
      "Epoch 81, 62% \t train_loss: 2.59 \t took: 0.05s\n",
      "Epoch 81, 75% \t train_loss: 2.66 \t took: 0.07s\n",
      "Epoch 81, 87% \t train_loss: 2.61 \t took: 0.05s\n",
      "Epoch 81, 100% \t train_loss: 2.59 \t took: 0.04s\n",
      "Validation loss = 2.07\n",
      "Epoch 82, 12% \t train_loss: 2.58 \t took: 0.10s\n",
      "Epoch 82, 25% \t train_loss: 2.56 \t took: 0.04s\n",
      "Epoch 82, 37% \t train_loss: 2.61 \t took: 0.04s\n",
      "Epoch 82, 50% \t train_loss: 2.61 \t took: 0.05s\n",
      "Epoch 82, 62% \t train_loss: 2.50 \t took: 0.06s\n",
      "Epoch 82, 75% \t train_loss: 2.62 \t took: 0.07s\n",
      "Epoch 82, 87% \t train_loss: 2.89 \t took: 0.05s\n",
      "Epoch 82, 100% \t train_loss: 2.66 \t took: 0.04s\n",
      "Validation loss = 2.07\n",
      "Epoch 83, 12% \t train_loss: 2.65 \t took: 0.10s\n",
      "Epoch 83, 25% \t train_loss: 2.42 \t took: 0.04s\n",
      "Epoch 83, 37% \t train_loss: 2.67 \t took: 0.04s\n",
      "Epoch 83, 50% \t train_loss: 2.61 \t took: 0.06s\n",
      "Epoch 83, 62% \t train_loss: 2.63 \t took: 0.07s\n",
      "Epoch 83, 75% \t train_loss: 2.75 \t took: 0.06s\n",
      "Epoch 83, 87% \t train_loss: 2.70 \t took: 0.04s\n",
      "Epoch 83, 100% \t train_loss: 2.50 \t took: 0.03s\n",
      "Validation loss = 2.07\n",
      "Epoch 84, 12% \t train_loss: 2.55 \t took: 0.11s\n",
      "Epoch 84, 25% \t train_loss: 2.72 \t took: 0.04s\n",
      "Epoch 84, 37% \t train_loss: 2.48 \t took: 0.04s\n",
      "Epoch 84, 50% \t train_loss: 2.58 \t took: 0.06s\n",
      "Epoch 84, 62% \t train_loss: 2.71 \t took: 0.05s\n",
      "Epoch 84, 75% \t train_loss: 2.64 \t took: 0.07s\n",
      "Epoch 84, 87% \t train_loss: 2.66 \t took: 0.04s\n",
      "Epoch 84, 100% \t train_loss: 2.54 \t took: 0.03s\n",
      "Validation loss = 2.04\n",
      "Epoch 85, 12% \t train_loss: 2.63 \t took: 0.10s\n",
      "Epoch 85, 25% \t train_loss: 2.43 \t took: 0.05s\n",
      "Epoch 85, 37% \t train_loss: 2.58 \t took: 0.05s\n",
      "Epoch 85, 50% \t train_loss: 2.61 \t took: 0.07s\n",
      "Epoch 85, 62% \t train_loss: 2.68 \t took: 0.07s\n",
      "Epoch 85, 75% \t train_loss: 2.88 \t took: 0.06s\n",
      "Epoch 85, 87% \t train_loss: 2.66 \t took: 0.05s\n",
      "Epoch 85, 100% \t train_loss: 2.60 \t took: 0.04s\n",
      "Validation loss = 2.07\n",
      "Epoch 86, 12% \t train_loss: 2.55 \t took: 0.10s\n",
      "Epoch 86, 25% \t train_loss: 2.58 \t took: 0.04s\n",
      "Epoch 86, 37% \t train_loss: 2.55 \t took: 0.06s\n",
      "Epoch 86, 50% \t train_loss: 2.73 \t took: 0.07s\n",
      "Epoch 86, 62% \t train_loss: 2.67 \t took: 0.05s\n",
      "Epoch 86, 75% \t train_loss: 2.48 \t took: 0.06s\n",
      "Epoch 86, 87% \t train_loss: 2.66 \t took: 0.05s\n",
      "Epoch 86, 100% \t train_loss: 2.75 \t took: 0.03s\n",
      "Validation loss = 2.05\n",
      "Epoch 87, 12% \t train_loss: 2.50 \t took: 0.11s\n",
      "Epoch 87, 25% \t train_loss: 2.71 \t took: 0.05s\n",
      "Epoch 87, 37% \t train_loss: 2.67 \t took: 0.04s\n",
      "Epoch 87, 50% \t train_loss: 2.58 \t took: 0.07s\n",
      "Epoch 87, 62% \t train_loss: 2.74 \t took: 0.04s\n",
      "Epoch 87, 75% \t train_loss: 2.53 \t took: 0.07s\n",
      "Epoch 87, 87% \t train_loss: 2.65 \t took: 0.04s\n",
      "Epoch 87, 100% \t train_loss: 2.61 \t took: 0.03s\n",
      "Validation loss = 2.04\n",
      "Epoch 88, 12% \t train_loss: 2.62 \t took: 0.10s\n",
      "Epoch 88, 25% \t train_loss: 2.59 \t took: 0.04s\n",
      "Epoch 88, 37% \t train_loss: 2.69 \t took: 0.04s\n",
      "Epoch 88, 50% \t train_loss: 2.74 \t took: 0.06s\n",
      "Epoch 88, 62% \t train_loss: 2.46 \t took: 0.06s\n",
      "Epoch 88, 75% \t train_loss: 2.68 \t took: 0.07s\n",
      "Epoch 88, 87% \t train_loss: 2.53 \t took: 0.05s\n",
      "Epoch 88, 100% \t train_loss: 2.69 \t took: 0.03s\n",
      "Validation loss = 2.04\n",
      "Epoch 89, 12% \t train_loss: 2.61 \t took: 0.10s\n",
      "Epoch 89, 25% \t train_loss: 2.65 \t took: 0.05s\n",
      "Epoch 89, 37% \t train_loss: 2.46 \t took: 0.05s\n",
      "Epoch 89, 50% \t train_loss: 2.62 \t took: 0.06s\n",
      "Epoch 89, 62% \t train_loss: 2.76 \t took: 0.06s\n",
      "Epoch 89, 75% \t train_loss: 2.64 \t took: 0.06s\n",
      "Epoch 89, 87% \t train_loss: 2.70 \t took: 0.04s\n",
      "Epoch 89, 100% \t train_loss: 2.49 \t took: 0.03s\n",
      "Validation loss = 2.03\n",
      "Epoch 90, 12% \t train_loss: 2.63 \t took: 0.11s\n",
      "Epoch 90, 25% \t train_loss: 2.50 \t took: 0.05s\n",
      "Epoch 90, 37% \t train_loss: 2.55 \t took: 0.04s\n",
      "Epoch 90, 50% \t train_loss: 2.65 \t took: 0.07s\n",
      "Epoch 90, 62% \t train_loss: 2.73 \t took: 0.04s\n",
      "Epoch 90, 75% \t train_loss: 2.69 \t took: 0.07s\n",
      "Epoch 90, 87% \t train_loss: 2.49 \t took: 0.06s\n",
      "Epoch 90, 100% \t train_loss: 2.67 \t took: 0.04s\n",
      "Validation loss = 2.05\n",
      "Epoch 91, 12% \t train_loss: 2.71 \t took: 0.10s\n",
      "Epoch 91, 25% \t train_loss: 2.59 \t took: 0.05s\n",
      "Epoch 91, 37% \t train_loss: 2.49 \t took: 0.05s\n",
      "Epoch 91, 50% \t train_loss: 2.48 \t took: 0.07s\n",
      "Epoch 91, 62% \t train_loss: 2.87 \t took: 0.06s\n",
      "Epoch 91, 75% \t train_loss: 2.65 \t took: 0.06s\n",
      "Epoch 91, 87% \t train_loss: 2.65 \t took: 0.04s\n",
      "Epoch 91, 100% \t train_loss: 2.70 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 92, 12% \t train_loss: 2.55 \t took: 0.12s\n",
      "Epoch 92, 25% \t train_loss: 2.67 \t took: 0.05s\n",
      "Epoch 92, 37% \t train_loss: 2.54 \t took: 0.05s\n",
      "Epoch 92, 50% \t train_loss: 2.64 \t took: 0.06s\n",
      "Epoch 92, 62% \t train_loss: 2.77 \t took: 0.05s\n",
      "Epoch 92, 75% \t train_loss: 2.59 \t took: 0.07s\n",
      "Epoch 92, 87% \t train_loss: 2.59 \t took: 0.05s\n",
      "Epoch 92, 100% \t train_loss: 2.62 \t took: 0.03s\n",
      "Validation loss = 2.05\n",
      "Epoch 93, 12% \t train_loss: 2.56 \t took: 0.11s\n",
      "Epoch 93, 25% \t train_loss: 2.54 \t took: 0.05s\n",
      "Epoch 93, 37% \t train_loss: 2.50 \t took: 0.04s\n",
      "Epoch 93, 50% \t train_loss: 2.83 \t took: 0.07s\n",
      "Epoch 93, 62% \t train_loss: 2.50 \t took: 0.04s\n",
      "Epoch 93, 75% \t train_loss: 2.65 \t took: 0.07s\n",
      "Epoch 93, 87% \t train_loss: 2.74 \t took: 0.05s\n",
      "Epoch 93, 100% \t train_loss: 2.63 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 94, 12% \t train_loss: 2.70 \t took: 0.10s\n",
      "Epoch 94, 25% \t train_loss: 2.39 \t took: 0.04s\n",
      "Epoch 94, 37% \t train_loss: 2.59 \t took: 0.04s\n",
      "Epoch 94, 50% \t train_loss: 2.86 \t took: 0.05s\n",
      "Epoch 94, 62% \t train_loss: 2.43 \t took: 0.06s\n",
      "Epoch 94, 75% \t train_loss: 2.71 \t took: 0.06s\n",
      "Epoch 94, 87% \t train_loss: 2.56 \t took: 0.05s\n",
      "Epoch 94, 100% \t train_loss: 2.70 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "Epoch 95, 12% \t train_loss: 2.53 \t took: 0.10s\n",
      "Epoch 95, 25% \t train_loss: 2.53 \t took: 0.05s\n",
      "Epoch 95, 37% \t train_loss: 2.63 \t took: 0.05s\n",
      "Epoch 95, 50% \t train_loss: 2.65 \t took: 0.07s\n",
      "Epoch 95, 62% \t train_loss: 2.62 \t took: 0.04s\n",
      "Epoch 95, 75% \t train_loss: 2.63 \t took: 0.07s\n",
      "Epoch 95, 87% \t train_loss: 2.72 \t took: 0.05s\n",
      "Epoch 95, 100% \t train_loss: 2.58 \t took: 0.03s\n",
      "Validation loss = 2.05\n",
      "Epoch 96, 12% \t train_loss: 2.65 \t took: 0.11s\n",
      "Epoch 96, 25% \t train_loss: 2.67 \t took: 0.05s\n",
      "Epoch 96, 37% \t train_loss: 2.59 \t took: 0.04s\n",
      "Epoch 96, 50% \t train_loss: 2.86 \t took: 0.07s\n",
      "Epoch 96, 62% \t train_loss: 2.50 \t took: 0.06s\n",
      "Epoch 96, 75% \t train_loss: 2.49 \t took: 0.06s\n",
      "Epoch 96, 87% \t train_loss: 2.54 \t took: 0.05s\n",
      "Epoch 96, 100% \t train_loss: 2.57 \t took: 0.03s\n",
      "Validation loss = 2.08\n",
      "Epoch 97, 12% \t train_loss: 2.72 \t took: 0.11s\n",
      "Epoch 97, 25% \t train_loss: 2.68 \t took: 0.04s\n",
      "Epoch 97, 37% \t train_loss: 2.59 \t took: 0.04s\n",
      "Epoch 97, 50% \t train_loss: 2.49 \t took: 0.06s\n",
      "Epoch 97, 62% \t train_loss: 2.70 \t took: 0.06s\n",
      "Epoch 97, 75% \t train_loss: 2.68 \t took: 0.06s\n",
      "Epoch 97, 87% \t train_loss: 2.57 \t took: 0.07s\n",
      "Epoch 97, 100% \t train_loss: 2.44 \t took: 0.03s\n",
      "Validation loss = 2.05\n",
      "Epoch 98, 12% \t train_loss: 2.49 \t took: 0.10s\n",
      "Epoch 98, 25% \t train_loss: 2.61 \t took: 0.04s\n",
      "Epoch 98, 37% \t train_loss: 2.65 \t took: 0.05s\n",
      "Epoch 98, 50% \t train_loss: 2.74 \t took: 0.06s\n",
      "Epoch 98, 62% \t train_loss: 2.49 \t took: 0.07s\n",
      "Epoch 98, 75% \t train_loss: 2.75 \t took: 0.06s\n",
      "Epoch 98, 87% \t train_loss: 2.55 \t took: 0.04s\n",
      "Epoch 98, 100% \t train_loss: 2.59 \t took: 0.03s\n",
      "Validation loss = 2.04\n",
      "Epoch 99, 12% \t train_loss: 2.51 \t took: 0.10s\n",
      "Epoch 99, 25% \t train_loss: 2.54 \t took: 0.05s\n",
      "Epoch 99, 37% \t train_loss: 2.59 \t took: 0.04s\n",
      "Epoch 99, 50% \t train_loss: 2.63 \t took: 0.06s\n",
      "Epoch 99, 62% \t train_loss: 2.67 \t took: 0.05s\n",
      "Epoch 99, 75% \t train_loss: 2.53 \t took: 0.07s\n",
      "Epoch 99, 87% \t train_loss: 2.64 \t took: 0.05s\n",
      "Epoch 99, 100% \t train_loss: 2.73 \t took: 0.03s\n",
      "Validation loss = 2.05\n",
      "Epoch 100, 12% \t train_loss: 2.56 \t took: 0.11s\n",
      "Epoch 100, 25% \t train_loss: 2.56 \t took: 0.04s\n",
      "Epoch 100, 37% \t train_loss: 2.69 \t took: 0.05s\n",
      "Epoch 100, 50% \t train_loss: 2.60 \t took: 0.09s\n",
      "Epoch 100, 62% \t train_loss: 2.67 \t took: 0.08s\n",
      "Epoch 100, 75% \t train_loss: 2.68 \t took: 0.05s\n",
      "Epoch 100, 87% \t train_loss: 2.49 \t took: 0.04s\n",
      "Epoch 100, 100% \t train_loss: 2.70 \t took: 0.03s\n",
      "Validation loss = 2.06\n",
      "==============================\n",
      "Training finished, took 127.72s\n",
      "Final Accuracies: \n",
      " overall: 31.340 \n",
      " class: {\n",
      "    \"plane\": 0.0,\n",
      "    \"car\": 68.51485148514851,\n",
      "    \"bird\": 28.515625,\n",
      "    \"cat\": 47.88732394366197,\n",
      "    \"deer\": 0.0,\n",
      "    \"dog\": 0.0,\n",
      "    \"frog\": 50.509164969450104,\n",
      "    \"horse\": 26.86868686868687,\n",
      "    \"ship\": 62.8968253968254,\n",
      "    \"truck\": 27.09551656920078\n",
      "}\n",
      "Predicted: horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "CNN = SimpleCNN()\n",
    "trainNet(CNN, batch_size=32, n_epochs=100, learning_rate=.01)\n",
    "overall_acc, class_acc = accuracy(CNN)\n",
    "print(\"Final Accuracies: \\n overall: {overall_acc:.3f} \\n class: {class_acc}\".format(\n",
    "    overall_acc=overall_acc, \n",
    "    class_acc=json.dumps(class_acc, indent=4)))\n",
    "\n",
    "outputs = CNN(img)\n",
    "# x = classes\n",
    "# y = np.ndarray.flatten(torch.nn.functional.softmax(outputs, dim=1).data.numpy())\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes()\n",
    "# plt.bar(x, y)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print(\"Predicted:\", classes[predicted[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  plane horse   cat   car\n",
      "Predicted:  plane   cat   cat plane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mattbev/.local/lib/python3.6/site-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "#Show images\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "outputs = CNN(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
